# ğŸ¦ Loan Approval Prediction  

This project tackles the **binary classification** problem of predicting whether a loan application will be **Approved or Rejected**.  
The analysis explores **EDA, data preprocessing, class imbalance handling, and multiple ML models** including **Decision Tree, Random Forest, Logistic Regression, and XGBoost**, followed by evaluation and comparison.  

---

### ğŸ“Œ Project Overview  

- **Data Preprocessing**: Encoded categorical variables (Graduate/Not Graduate, Yes/No, Approved/Rejected), handled missing values, and split the dataset into training and test sets.  
- **Exploratory Data Analysis (EDA)**: Generated correlation heatmaps and boxplots to understand variable relationships.  
- **Class Imbalance Handling**: Applied **SMOTE** (Synthetic Minority Oversampling Technique) to balance target classes.  
- **Models Trained**: Logistic Regression, Decision Tree, Random Forest, and XGBoost.  
- **Evaluation**: Used accuracy, precision, recall, F1-score, and ROC-AUC to measure performance.  

---

### ğŸ› ï¸ Tech Stack  

- **Python**  
- **Pandas, NumPy** â†’ Data manipulation and preprocessing  
- **Matplotlib, Seaborn** â†’ Data visualization  
- **Scikit-learn** â†’ Model training, evaluation, and hyperparameter tuning  
- **Imbalanced-learn (SMOTE)** â†’ Oversampling for imbalanced classes  
- **XGBoost** â†’ Gradient boosting classifier  

---

### ğŸ“‚ Dataset  

The dataset contains demographic and financial details of applicants, including:  

- Applicantâ€™s **education level** (Graduate / Not Graduate)  
- **Self-employed status** (Yes / No)  
- **Loan status** (Approved / Rejected â€“ target variable)  
- Other numerical and categorical features affecting loan approval.  

---

### ğŸ“Š Data & Model Analysis  

- Cleaned categorical inconsistencies (e.g., leading/trailing spaces).  
- Applied **correlation heatmaps** and **boxplots** to visualize relationships.  
- Balanced the target variable using **SMOTE**.  
- Trained multiple ML models to compare performance.  

---

### ğŸ¤– Models Implemented  

- **Logistic Regression** â†’ Simple linear classifier for baseline performance  
- **Decision Tree** â†’ Interpretable tree-based classifier  
- **Random Forest** â†’ Ensemble bagging model for robust predictions  
- **XGBoost** â†’ Gradient boosting model optimized for performance  

---

### ğŸ“ˆ Model Evaluation & Insights  

- **Accuracy, Precision, Recall, and F1-score** reported for all models.  
- Random Forest and XGBoost generally showed the **best trade-off between recall and precision**.  

---

### ğŸ“· Visualizations  

- Correlation heatmap of features  
- Boxplots of key variables  
